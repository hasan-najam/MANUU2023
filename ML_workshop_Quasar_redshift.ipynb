{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4LlaZmZfBWR"
   },
   "source": [
    "# Machine Learning workshop "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KvS4oKNdfwgK"
   },
   "source": [
    "# Aim: to  use the SDSS DR16 quasar catalog to predict the redshift of unknown quasars.\n",
    "\n",
    "We will use u,g,r,i,z magnitudes and the corresponding extinction values to build a regresson model that can predict the redshift of quasars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Lh6X06IQHyD3"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-58701275455c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/data.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Read the data into a Pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from google.colab import drive \n",
    "file_path = '/content/drive/My Drive/data.csv' \n",
    "\n",
    "# Read the data into a Pandas DataFrame\n",
    "#df = pd.read_csv(file_path)\n",
    "\n",
    "# Print the first 5 rows of the data\n",
    "#print(df.head())\n",
    "\n",
    "\n",
    "############## Another way #############\n",
    "#from google.colab import files\n",
    "\n",
    "#uploaded = files.upload()\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_SWoJyPMJoxt"
   },
   "source": [
    "# **Reading the data using pandas**\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "HMz3ift6IQY2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "df = pd.read_csv('https://ff6b8c1c-c22c-4c69-b34c-fa3dbd3e97b5.filesusr.com/ugd/9f63fe_51f323a9cdc4405a91fa58fbb4011dff.csv?dn=DR16Q_NonBALs_ASIML.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FDxrxwOYKREa"
   },
   "source": [
    "# **Explore the dataset**\n",
    "\n",
    "This code calls the head() method on the data pandas dataframe, which returns the first 5 rows (by default) of the dataframe. The head() method provides a quick way to preview the data in the dataframe, which can be helpful in checking the data format and structure, and making sure that the data has been loaded correctly. The number of rows displayed by the head() method can be adjusted by passing a desired number as an argument, such as data.head(10) to display the first 10 rows of the dataframe.\n",
    "\n",
    "Note that the PSFMAG and EXTINCTION parameters are given as tuples.  We will have to split thpse tuples in to individual parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "id": "f1zq0YHMdJZW",
    "outputId": "b34bbf19-00ac-4ef9-c612-6e9eaee7fc4c"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "48wKkvptK2wh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cQKpgJ6Kyzz"
   },
   "source": [
    "# **Redefining a new pandas DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FOaUnyD-b-Wa"
   },
   "outputs": [],
   "source": [
    "# Initialize a pandas DataFrame with the default values\n",
    "data = pd.DataFrame()\n",
    "\n",
    "# Add a column to the DataFrame with the values from the 'SDSS_NAME' column in the 'df' DataFrame\n",
    "data['SDSS_NAME'] = df['SDSS_NAME']\n",
    "\n",
    "# Add a column to the DataFrame with the values from the 'RA' column in the 'df' DataFrame\n",
    "data['RA'] = df['RA']\n",
    "\n",
    "# Add a column to the DataFrame with the values from the 'DEC' column in the 'df' DataFrame\n",
    "data['DEC'] = df['DEC']\n",
    "\n",
    "# Add a column to the DataFrame with the values from the 'PLATE' column in the 'df' DataFrame\n",
    "data['PLATE'] = df['PLATE']\n",
    "\n",
    "# Add a column to the DataFrame with the values from the 'MJD' column in the 'df' DataFrame\n",
    "data['MJD']  = df['MJD']\n",
    "\n",
    "# Add a column to the DataFrame with the values from the 'FIBERID' column in the 'df' DataFrame\n",
    "data['FIBERID'] = df['FIBERID']\n",
    "\n",
    "# Add a column to the DataFrame with the values from the 'Z_VI' column in the 'df' DataFrame\n",
    "data['Z_VI'] = df['Z_VI']\n",
    "\n",
    "# Add a column to the DataFrame with the values from the first item of the 'PSFMAG' column in the 'df' DataFrame, converted to float type\n",
    "data['U_MAG'] = [ float(df['PSFMAG'][i].split(',')[0].split('(')[1]) for i in range(len(df))]\n",
    "\n",
    "# Add a column to the DataFrame with the values from the second item of the 'PSFMAG' column in the 'df' DataFrame, converted to float type\n",
    "data['G_MAG'] = [ float(df['PSFMAG'][i].split(',')[1]) for i in range(len(df))]\n",
    "\n",
    "# Add a column to the DataFrame with the values from the third item of the 'PSFMAG' column in the 'df' DataFrame, converted to float type\n",
    "data['R_MAG'] = [ float(df['PSFMAG'][i].split(',')[2]) for i in range(len(df))]\n",
    "\n",
    "# Add a column to the DataFrame with the values from the fourth item of the 'PSFMAG' column in the 'df' DataFrame, converted to float type\n",
    "data['I_MAG'] = [ float(df['PSFMAG'][i].split(',')[3]) for i in range(len(df))]\n",
    "\n",
    "# Add a column to the DataFrame with the values from the fifth item of the 'PSFMAG' column in the 'df' DataFrame, converted to float type\n",
    "data['Z_MAG'] = [ float(df['PSFMAG'][i].split(',')[4].split(')')[0]) for i in range(len(df))]\n",
    "\n",
    "# Similarly do for Extinction\n",
    "data['U_EXT'] = [ float(df['EXTINCTION'][i].split(',')[0].split('(')[1]) for i in range(len(df))]\n",
    "data['G_EXT'] = [ float(df['EXTINCTION'][i].split(',')[1]) for i in range(len(df))]\n",
    "data['R_EXT'] = [ float(df['EXTINCTION'][i].split(',')[2]) for i in range(len(df))]\n",
    "data['I_EXT'] = [ float(df['EXTINCTION'][i].split(',')[3]) for i in range(len(df))]\n",
    "data['Z_EXT'] = [ float(df['EXTINCTION'][i].split(',')[4].split(')')[0]) for i in range(len(df))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wPiASR6MLFHG"
   },
   "source": [
    "# **Printing the dataframe statistics**\n",
    "The describe() method on the data pandas dataframe returns various statistical information about the numerical columns in the dataframe. The output provides count, mean, standard deviation, minimum value, 25th percentile, median (50th percentile), 75th percentile, and maximum value for each numerical column in the dataframe. The describe() method gives a quick and easy way to get an overview of the numerical data in the dataframe, which can be helpful in understanding the distribution and range of values for each column.\n",
    "\n",
    "Note that for some of the parameters there are -9999 values for eg, Z_VI, all magnitudes. These -9999 values are basically unreliable entries and need to be cleaned before any ML exercise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "itkzTp4vdtgm",
    "outputId": "b197c424-de84-412b-9056-0af3f8dbd981"
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5ACB6ytLj-X"
   },
   "source": [
    "# **Histograms of parameters in the dataframe**\n",
    "This code calls the hist() method on the data pandas dataframe, which generates a histogram for each numerical column in the dataframe. The histograms provide a graphical representation of the distribution of values for each column, and help to quickly identify the shape of the distribution and any potential outliers. By default, the hist() method generates histograms for all numerical columns in the dataframe, but the columns to be plotted can be specified by passing a list of column names as an argument, such as data.hist(['col1', 'col2']). The hist() method is a useful tool for exploratory data analysis and for gaining a better understanding of the structure and distribution of the data.\n",
    "\n",
    "This is is nice way to explore the input parameters. It is clear that the -9999 values are creating a skewed distributions. We will have to clean the data to remove these absurd values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 879
    },
    "id": "o-KYuRUVhWfn",
    "outputId": "e2dd1875-5859-49a9-aed0-a6510d860bc8"
   },
   "outputs": [],
   "source": [
    "data.hist(bins=50,figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jh8La4hcMGLz"
   },
   "source": [
    "# **Cleaning the data**\n",
    "This step removes the negative values from the input parameters.\n",
    "\n",
    "This code removes all rows in the data pandas dataframe where the value for each of the specified columns (Z_VI, U_MAG, G_MAG, R_MAG, I_MAG, Z_MAG, U_EXT, G_EXT, R_EXT, I_EXT, Z_EXT) is less than 0. This is done using the drop method with the inplace argument set to True, which updates the data dataframe in place and does not return a new dataframe. The method data.index[data['column'] < 0] returns the index of all rows where the value of the specified column is less than 0. The drop method is called once for each of the specified columns, removing the corresponding rows where the condition is met. This operation is useful for removing any invalid or missing data from the dataframe, which could cause errors or affect the accuracy of subsequent analyses.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LRjLWsIYiQHp"
   },
   "outputs": [],
   "source": [
    "data.drop(data.index[data['Z_VI'] <0], inplace = True)\n",
    "data.drop(data.index[data['U_MAG'] <0], inplace = True)\n",
    "data.drop(data.index[data['G_MAG'] <0], inplace = True)\n",
    "data.drop(data.index[data['R_MAG'] <0], inplace = True)\n",
    "data.drop(data.index[data['I_MAG'] <0], inplace = True)\n",
    "data.drop(data.index[data['Z_MAG'] <0], inplace = True)\n",
    "data.drop(data.index[data['U_EXT'] <0], inplace = True)\n",
    "data.drop(data.index[data['G_EXT'] <0], inplace = True)\n",
    "data.drop(data.index[data['R_EXT'] <0], inplace = True)\n",
    "data.drop(data.index[data['I_EXT'] <0], inplace = True)\n",
    "data.drop(data.index[data['Z_EXT'] <0], inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RiWklTDkMTJ3"
   },
   "source": [
    "# **Print the statistics to ensure that the negative values are gone**\n",
    "Note that the count has significantly reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "uvbmcHrGjJOG",
    "outputId": "f79e6453-6d1f-4cd7-d652-b5ace6546b40"
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uuytjnqqMkUC"
   },
   "source": [
    "# **Explore the correlations between output label and input parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qq6ZV-pjlpJo",
    "outputId": "736999e2-9bac-436b-9a01-d7d7270babde"
   },
   "outputs": [],
   "source": [
    "# Calculating the correlation matrix\n",
    "# The correlation matrix measures the linear relationship between all the features in the data\n",
    "# It gives us a score between -1 and 1, with 1 meaning a perfect positive linear relationship, 0 meaning no linear relationship, and -1 meaning a perfect negative linear relationship\n",
    "\n",
    "corr_matrix = data[['Z_VI','U_MAG','G_MAG','R_MAG','I_MAG','Z_MAG','U_EXT','G_EXT','R_EXT','I_EXT','Z_EXT']].corr()\n",
    "\n",
    "# Sorting the values of correlation of Z_VI with other features\n",
    "# Sorting in descending order to see which features have the strongest positive linear relationship with Z_VI\n",
    "# Positive linear relationship means that if Z_VI increases, the other feature also increases\n",
    "\n",
    "corr_matrix['Z_VI'].sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XYIh9o-uMv8s"
   },
   "source": [
    "# **Create attribute combinations**\n",
    "Here we will create new input parameters which are actually the colors, i.e. magnitude differences.\n",
    "\n",
    "The code creates four new columns in the data DataFrame: 'U-G_COLOR', 'G-R_COLOR', 'R-I_COLOR', and 'I-Z_COLOR'.\n",
    "These new columns represent the color indices calculated as the difference between the magnitudes in different filters.\n",
    "For example, 'U-G_COLOR' is calculated as the difference between the 'U_MAG' and 'G_MAG' columns.\n",
    "The color indices can provide additional information about the properties of the objects in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YekZNpIXknFq"
   },
   "outputs": [],
   "source": [
    "data['U-G_COLOR'] = data['U_MAG'] - data['G_MAG']\n",
    "data['G-R_COLOR'] = data['G_MAG'] - data['R_MAG']\n",
    "data['R-I_COLOR'] = data['R_MAG'] - data['I_MAG']\n",
    "data['I-Z_COLOR'] = data['I_MAG'] - data['Z_MAG']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIHMHbD0NB2M"
   },
   "source": [
    "# **Histograms of cleaned dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 879
    },
    "id": "4J2PY_cIjwUk",
    "outputId": "3b4d4d29-d343-41db-9d5c-1be29d7b0f83"
   },
   "outputs": [],
   "source": [
    "data.hist(bins=50,figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-8J7vY93Hnt3"
   },
   "outputs": [],
   "source": [
    "#from google_drive_downloader import GoogleDriveDownloader as gd\n",
    "#gd.download_file_from_google_drive(file_id='1UT2BCf-IDUEpvTmcU4bq6nDcY3Ayw5vJ', dest_path='./data/stamps_noise.npy', unzip=False)\n",
    "#gd.download_file_from_google_drive(file_id='1cZaMCA0z_nPX6GB_meLGouwOidEROcwc', dest_path='./data/stamps_sources.npy', unzip=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GKM6Fv0NI87"
   },
   "source": [
    "# **Correlations of the new data with colors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tFQ3LrKMlMAY",
    "outputId": "e1c62c91-0c31-4c0b-cc0c-01559d4f1ba6"
   },
   "outputs": [],
   "source": [
    "corr_matrix = data[['Z_VI','U_MAG','G_MAG','R_MAG','I_MAG','Z_MAG','U_EXT','G_EXT','R_EXT','I_EXT','Z_EXT','U-G_COLOR','G-R_COLOR','R-I_COLOR','I-Z_COLOR']].corr()\n",
    "corr_matrix['Z_VI'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVXVLrFPNeu-"
   },
   "source": [
    "# **Scatter matrix to explore the correlations between parameters**\n",
    "\n",
    "The following code imports the scatter_matrix function from pandas.plotting module.\n",
    "The variable 'attributes' is defined as a list of columns from the data frame that are to be plotted in the scatter matrix.\n",
    "The scatter_matrix function takes in the data frame with only the specified columns and creates a scatter matrix plot of all possible combinations of the specified columns.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500
    },
    "id": "ETAjQYb6hVju",
    "outputId": "a8f312da-02d4-43dc-9310-9b0b7ef2acab"
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "attributes = ['Z_VI','U-G_COLOR','G-R_COLOR','U_MAG','R_MAG','I_EXT']\n",
    "scatter_matrix(data[attributes],figsize=(12,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dw74-fjHWZdw"
   },
   "source": [
    "# **Feature Scaling**\n",
    "It is better to have the input parameters distributed between 0 and 1. Otherwise the difference in the values, for eg, in our case magnitudes are distributed around 20 and extintion values are distributed around 1. To enable the algorithm to give equal weightage to all parameters, it is  good to scale the features to a common values. \n",
    "\n",
    "It is recommended to distribute values between 0 and 1. Two approaches are common, MinMaxScaler and StandardScaler\n",
    "\n",
    "MinMaxScaler : tries to make the minimum value 0 and maximum value 1 and distribute all other values accordingly. Values are shifted and rescaled so that they end up ranging from 0 and 1\n",
    "\n",
    "StandardScaler : substracts the mean from each values and then divided by the standard deviation so that the resulting distribution has unit variance and zero mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p12xRYlxIPOg",
    "outputId": "e7c860d6-1673-4631-adc4-d0feafbb8a93"
   },
   "outputs": [],
   "source": [
    "#The following code imports the StandardScaler class from the sklearn.preprocessing module.\n",
    "#The StandardScaler class is then instantiated and assigned to the scaler variable.\n",
    "#Finally, the fit method of the scaler object is called on the specified columns of the data DataFrame,\n",
    "#which contains the magnitudes and colors of astronomical objects. This prepares the scaler object to perform normalization on these features in future processing.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data[['U_MAG','G_MAG','R_MAG','I_MAG','Z_MAG','U_EXT','G_EXT','R_EXT','I_EXT','Z_EXT','U-G_COLOR','G-R_COLOR','R-I_COLOR','I-Z_COLOR']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6ZKy1qgiz9G"
   },
   "source": [
    "This following line of code creates a new DataFrame, named scaled_data, which contains the scaled values of the columns ['U_MAG','G_MAG','R_MAG','I_MAG','Z_MAG','U_EXT','G_EXT','R_EXT','I_EXT','Z_EXT','U-G_COLOR','G-R_COLOR','R-I_COLOR','I-Z_COLOR'] from the original DataFrame data. The scaling of the data is done using the StandardScaler object that was fit on the same columns in the previous line of code. The result of the scaling is a normalized data with a mean of 0 and standard deviation of 1, which can be useful for certain machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NClJvs0noEWm"
   },
   "outputs": [],
   "source": [
    "scaled_data= pd.DataFrame(scaler.transform(data[['U_MAG','G_MAG','R_MAG','I_MAG','Z_MAG','U_EXT','G_EXT','R_EXT','I_EXT','Z_EXT','U-G_COLOR','G-R_COLOR','R-I_COLOR','I-Z_COLOR']]),\n",
    "                          columns=['U_MAG','G_MAG','R_MAG','I_MAG','Z_MAG','U_EXT','G_EXT','R_EXT','I_EXT','Z_EXT','U-G_COLOR','G-R_COLOR','R-I_COLOR','I-Z_COLOR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVD3o5KZYski"
   },
   "source": [
    "# **Explore the scaled data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "6ivCn1b0pbdW",
    "outputId": "2521eddb-3f11-4b6a-c7d9-693c8ef14327"
   },
   "outputs": [],
   "source": [
    "scaled_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 879
    },
    "id": "3BPVeiB8qAKR",
    "outputId": "fbb9318f-e113-484d-baa1-b780d5d9694e"
   },
   "outputs": [],
   "source": [
    "scaled_data.hist(bins=50,figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VFZEba2fi5j3"
   },
   "outputs": [],
   "source": [
    "#Add back Z_VI\n",
    "scaled_data['Z_VI'] = data['Z_VI']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XscLxhr5YyXz"
   },
   "source": [
    "#**Note**\n",
    " We are not using the feature scaling here as we already saw that the extinction has small correlations with redshift. But, you can explore the following algorithm with scaled data and see what difference it makes. For neural networks, it is recommended to use feature scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJEMupk-ZWaO"
   },
   "source": [
    "# **Copying the data to a new dataframe to exclude irrelevent features**\n",
    "Excluding SDSS_NAME, RA,DEC, PLATE,MJD, FIBERID as these are not expected to influence the redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQiftBTGrGHO"
   },
   "outputs": [],
   "source": [
    "#new_data = data[['U_MAG','G_MAG','R_MAG','I_MAG','Z_MAG','U_EXT','G_EXT','R_EXT','I_EXT','Z_EXT','U-G_COLOR','G-R_COLOR','R-I_COLOR','I-Z_COLOR']]\n",
    "new_data = data[['U_MAG','G_MAG','R_MAG','I_MAG','Z_MAG','U-G_COLOR','G-R_COLOR','R-I_COLOR','I-Z_COLOR']]\n",
    "\n",
    "new_data.head()\n",
    "new_data_labels = data['Z_VI']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mX6dJDAYZrZf"
   },
   "source": [
    "# **Linear Regression**\n",
    "The following line of code imports the LinearRegression class from the sklearn.linear_model library. Then, it creates an instance of the LinearRegression class called lin_reg. The fit method is called on lin_reg and passed two arguments new_data and new_data_labels. This trains the linear regression model using the new_data and new_data_labels arrays and finds the best line of fit to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PS_NCT7Qqtoc",
    "outputId": "d77576cf-947e-48d8-9ddb-847e7dd779d2"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(new_data,new_data_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JiWgN7CZ393"
   },
   "source": [
    "# **Reserving some data for checking the predictions**\n",
    " Here we are allocating the first fifteen entries as the test set.\n",
    " But, ideally we should split the dataset into test set and train set and evaluate the performance on the test set.\n",
    "\n",
    " We will do that when we train an neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q4lKtLE7t9Zd",
    "outputId": "e54d101b-de22-400f-8b52-3c8a44a01f5e"
   },
   "outputs": [],
   "source": [
    "some_data = new_data.iloc[:15]\n",
    "some_data_labels = new_data_labels.iloc[:15]\n",
    "print(\"LinReg Predictions\", lin_reg.predict(some_data))\n",
    "print('Actual Labels', list(some_data_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ganBGvtnagxk"
   },
   "source": [
    "# **Checking the predictions**\n",
    "See below that the rms error is 0.4 in redshift which is not a great solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TthOqLuhZ3Yo"
   },
   "source": [
    "\n",
    "\n",
    "The following code is evaluating the performance of the linear regression model that was trained on the new_data and new_data_labels.\n",
    "Firstly, the mean_squared_error is imported from scikit-learn library to evaluate the error between actual and predicted values.\n",
    "Then the predictions are made using the trained linear regression model on the \"some_data\".\n",
    "The mean squared error is calculated by comparing the actual \"some_data_labels\" with the predicted values.\n",
    "The final step is to find the root mean squared error (RMSE) which is the square root of the mean squared error.\n",
    "This RMSE value represents the average deviation between the actual and predicted values.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H877dSOUu5VG",
    "outputId": "ff781dbd-4422-4429-a420-16a075d7ccac"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "some_data_predictions = lin_reg.predict(some_data)\n",
    "lin_mse = mean_squared_error(some_data_labels,some_data_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse,lin_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIkDXDWNay4W"
   },
   "source": [
    "# **DecisonTree Regression**\n",
    "---\n",
    "Decision Tree Regression is a supervised machine learning algorithm used for solving regression problems, where the goal is to predict a continuous target variable based on a set of input features.\n",
    "\n",
    "It works by constructing a tree-like model that breaks down the input data into smaller and smaller subsets based on certain conditions. The conditions are chosen based on the feature values, such that the target variable is as close as possible to the actual values. The final prediction is obtained by navigating the tree to the leaf node that corresponds to the input features, and using the mean value of the target variable for the samples in that node.\n",
    "\n",
    "The key advantage of decision tree regression is its interpretability, as it provides a clear and concise explanation of the relationship between the input features and the target variable. However, decision trees can easily become too complex and overfit to the training data, leading to poor performance on unseen data.\n",
    "\n",
    "Despite its limitations, decision tree regression is a useful algorithm for exploring and understanding complex datasets, and can also be used as a base algorithm for more complex models, such as random forests or gradient boosting.\n",
    "\n",
    "---\n",
    "\n",
    "The code is using the DecisionTreeRegressor class from the scikit-learn library to train a decision tree model on the data. The fit method is then used to fit the model to the data. The model is then used to make predictions on some_data using the predict method. The mean_squared_error function from the metrics module is used to calculate the mean squared error between the actual values and the predicted values. The square root of this value is then calculated and stored in the variable tree_rmse, which represents the root mean squared error for the decision tree model.\n",
    "\n",
    "The regression is resulting in zero MSE, which means the model is overfitting the data. It is important to evaluate the score k-fold using cross-validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rlMUfw87v6fA",
    "outputId": "31d41b92-b8bc-4671-901d-763d179b805d"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(new_data,new_data_labels)\n",
    "tree_some_data_predictions = tree_reg.predict(some_data)\n",
    "print(\"TreeReg Predictions\", tree_reg.predict(some_data))\n",
    "print('Actual Labels', list(some_data_labels))\n",
    "tree_mse = mean_squared_error(some_data_labels,tree_some_data_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WizKciF7bIuS"
   },
   "source": [
    "# **Random Forest Regression**\n",
    "#Note : This takes some time to train. be patient !!!\n",
    "---\n",
    "Random Forest Regression is a type of ensemble learning method for regression problems in machine learning. It is an extension of decision tree regression, and combines the predictions of multiple decision trees to produce a more accurate and robust prediction.\n",
    "\n",
    "In a random forest regressor, many decision trees are trained on random subsets of the training data. At prediction time, the input features are passed through each of the trees, and the average of the individual tree predictions is taken as the final prediction. This combination of multiple trees helps to reduce overfitting and increase the overall performance of the model.\n",
    "\n",
    "The randomness in a random forest regressor comes from two sources: (1) a random subset of the training data is used to train each tree, and (2) a random subset of the available features is used to split each node in each tree. These random selections help to create a diverse set of trees, each with different structures and predictions, and to reduce overfitting by avoiding reliance on any one feature or group of features.\n",
    "\n",
    "Random Forest Regression is a versatile and widely used algorithm that can handle non-linear relationships between features and target variables, and can also be applied to high-dimensional data. It is relatively easy to use, robust to overfitting, and provides important feature importances that can help to identify the most influential features in the dataset.\n",
    "\n",
    "\n",
    "---\n",
    "This code imports the RandomForestRegressor class from the scikit-learn library's ensemble module.\n",
    "The model is then created and fit to the new_data and new_data_labels.\n",
    "The model is then used to make predictions for the 'some_data' input.\n",
    "The mean squared error and root mean squared error are calculated and displayed for the forest regression model.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Note that the RandomForest Regressor actually performs better than the linear regressor. Rms error is 0.1 in Random Forest Regressor as compared to 0.4 in Linear Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y6EpB66AyGQQ",
    "outputId": "eb6176c3-af54-455c-9798-a35caf23df99"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(new_data,new_data_labels)\n",
    "forest_some_data_predictions = forest_reg.predict(some_data)\n",
    "print(\"ForestReg Predictions\", forest_reg.predict(some_data))\n",
    "print('Actual Labels', list(some_data_labels))\n",
    "forest_mse = mean_squared_error(some_data_labels,forest_some_data_predictions)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "forest_rmse,forest_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tYwy35a2GjO"
   },
   "source": [
    "# **Examining the feature importance of two models**\n",
    "This code is visualizing the feature importance of two models, a random forest regressor and a decision tree regressor, on the same dataset. The feature importances of both models are stored in a pandas dataframe, feature_importance. The rfc column holds the feature importances of the random forest model, while the dt column holds the feature importances of the decision tree model. The dataframe is sorted based on the rfc feature importances in ascending order, and a horizontal bar plot is created to compare the feature importances of both models. The y-axis of the plot is the features' names, and the x-axis is the feature importances. The bar plot is created using the barh method of the matplotlib ax object, with the red bars representing the random forest feature importances and the blue bars representing the decision tree feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "id": "rVPbAcCg0e77",
    "outputId": "74c0f7b0-9266-4026-c27a-39cd8a2930a1"
   },
   "outputs": [],
   "source": [
    "feature_importance=pd.DataFrame({\n",
    "    'rfc':forest_reg.feature_importances_,\n",
    "    'dt':tree_reg.feature_importances_\n",
    "},index=new_data.columns)\n",
    "feature_importance.sort_values(by='rfc',ascending=True,inplace=True)\n",
    "\n",
    "index = np.arange(len(feature_importance))\n",
    "fig, ax = plt.subplots(figsize=(18,8))\n",
    "rfc_feature=ax.barh(index,feature_importance['rfc'],0.5,color='red',label='Random Forest')\n",
    "dt_feature=ax.barh(index+0.4,feature_importance['dt'],0.5,color='blue',label='Decision Tree')\n",
    "ax.set(yticks=index+0.4,yticklabels=feature_importance.index,title='Feature Importance of Random Forests vs Decision Trees')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "fD2Dk1T87YEA"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This function calculates and displays the root mean squared error (RMSE) \n",
    "from a given set of scores. It first calculates the square root of the negative \n",
    "values of the scores, which gives us the RMSE. It then calculates the mean and\n",
    "standard deviation of the RMSE.\n",
    "'''\n",
    "def display_scores(scores):\n",
    "  print(\"MSE Scores:\", -scores)\n",
    "  print(\"MSE Mean:\",-scores.mean())\n",
    "  print('MSE Std Dev:', scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FHitfaywc84M"
   },
   "source": [
    "# **Cross validation**\n",
    "K-fold cross validation is a widely used model evaluation technique in machine learning. It is used to assess the performance of a model on unseen data. In this technique, the original dataset is split into k parts (or folds) and the model is trained k times using k-1 parts for training and the remaining part for testing. This process is repeated k times such that each part is used for testing once. The average performance of the model across all k iterations is used to evaluate the model. The performance of the model is then calculated as the average of the performance metric across all k folds, which provides a more robust evaluation of the model's generalization performance compared to using a single validation set. This technique helps to reduce overfitting and ensure that the model is able to generalize well to new data. Thus, improving the accuracy of the model.\n",
    "\n",
    "![grid_search_cross_validation.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "29-J8ziN5wq7",
    "outputId": "e8cd4c26-c6bb-4507-b965-b225122fd175"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The code is performing cross-validation on linear regression and random forest regression models.\n",
    "For each model, cross-val_score function from sklearn.model_selection module is used to evaluate \n",
    "the model's performance using neg_mean_squared_error as the scoring metric. The number of folds \n",
    "for cross-validation is set to 5 (cv=5).\n",
    "The RMSE scores are then calculated by taking the square root of the negated scores.\n",
    "Finally, the display_scores function is called to display the scores and its statistics such as mean and standard deviation.\n",
    "'''\n",
    "from sklearn.model_selection import cross_val_score\n",
    "lin_scores = cross_val_score(lin_reg,new_data,new_data_labels,scoring=\"neg_mean_squared_error\",cv=5)\n",
    "lin_rmse_scores=np.sqrt(-lin_scores)\n",
    "#print('RMSE Scores',lin_rmse_scores)\n",
    "\n",
    "#Cross-validation for Forest Regressor\n",
    "#keep cv as minimum as it will take a lot of time to get the results otherwise\n",
    "forest_scores = cross_val_score(forest_reg,new_data,new_data_labels,scoring=\"neg_mean_squared_error\",cv=3)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "#print(forest_rmse_scores)\n",
    "print('=='*5,\"Linear Reg Scores\",\"==\"*5)\n",
    "print(display_scores(lin_scores))\n",
    "print('=='*5,\"Forest Reg Scores\",\"==\"*5)\n",
    "print(display_scores(forest_scores))\n",
    "\n",
    "lin_mean_mse = -lin_scores.mean()\n",
    "lin_std_mse = lin_scores.std()\n",
    "forest_mean_mse = -forest_scores.mean()\n",
    "forest_std_mse = forest_scores.std()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i0ffacZieeqq"
   },
   "source": [
    "========== Linear Reg Scores ==========\n",
    "RMSE Scores: [0.31704958 0.29051165 0.28745435 0.28843465 0.28937957]\n",
    "RMSE Mean: 0.2945659589876204\n",
    "RMSE Std Dev: 0.011287313422442925\n",
    "========== Forest Reg Scores ==========\n",
    "RMSE Scores: [0.24297035 0.21188608 0.22943774]\n",
    "RMSE Mean: 0.22809805564285804\n",
    "RMSE Std Dev: 0.012725407238263238\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "7dzjTuPkfS1u",
    "outputId": "93e2df9d-8d38-441c-d086-92cf34a2b9c5"
   },
   "outputs": [],
   "source": [
    "print([0.31704958**2, 0.29051165**2, 0.28745435**2, 0.28843465**2, 0.28937957**2])\n",
    "print(0.2945659589876204**2,0.011287313422442925**2)\n",
    "print([0.24297035**2, 0.21188608**2, 0.22943774**2])\n",
    "print(0.22809805564285804**2,0.012725407238263238**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mq-e4bRPem9E"
   },
   "source": [
    "# **Cross-validation for DecisonTree**\n",
    "\n",
    "In the case of decision tree algorithms, cross-validation can be particularly useful for mitigating overfitting, which is a common problem with decision trees. Overfitting occurs when a model becomes too complex and starts to capture the noise in the training data rather than the underlying patterns. This results in poor generalization performance on unseen data.\n",
    "\n",
    "By using cross-validation, we can obtain a more reliable estimate of the performance of a decision tree algorithm on unseen data. The basic idea is to divide the available data into several folds, train the model on a portion of the data (the training set), and evaluate the performance on the remaining portion (the validation set). This process is repeated multiple times, using different portions of the data for training and validation, and the average performance across the folds is used as the final performance estimate.\n",
    "\n",
    "By using cross-validation, we can avoid overfitting to the training data, get a better idea of how the algorithm will perform on new, unseen data, and identify the optimal number of decision trees to use in the ensemble.\n",
    "\n",
    "---\n",
    "See how the MSE now are more sensible. Earlier we got 0 MSE which is absurd. Always use cross-validation to check the robustness of the Fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "4dqK9PIEACk-",
    "outputId": "e96c41ce-5eaf-4014-836d-2507675f2776"
   },
   "outputs": [],
   "source": [
    "tree_scores = cross_val_score(tree_reg,new_data,new_data_labels,scoring=\"neg_mean_squared_error\",cv=5)\n",
    "tree_rmse_scores = np.sqrt(-tree_scores)\n",
    "print(tree_rmse_scores)\n",
    "print('=='*5,\"Tree Reg Scores\",\"==\"*5)\n",
    "display_scores(tree_scores)\n",
    "tree_mean_mse = -tree_scores.mean()\n",
    "tree_std_mse = tree_scores.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PBrevnOie6Vi"
   },
   "source": [
    "# **Simple ANN to do the regression**\n",
    "---\n",
    "An Artificial Neural Network (ANN) is a machine learning model that is inspired by the structure and function of the human brain. A simple ANN for regression can be implemented using the following steps:\n",
    "\n",
    "Data preparation: The first step is to prepare the data for the model. This includes splitting the data into training and test sets, normalizing or scaling the input features, and converting the target variable into a suitable format.\n",
    "\n",
    "Model definition: Next, the structure of the ANN is defined using a programming library such as TensorFlow or Keras. A simple ANN for regression typically has an input layer, one or more hidden layers, and an output layer. The input layer receives the input features, and the output layer produces the predicted target value. The hidden layers perform the non-linear transformations that enable the model to capture complex relationships between the features and target.\n",
    "\n",
    "Model compilation: Once the model is defined, it is compiled by specifying the loss function, the optimizer, and any other relevant parameters. For a regression problem, the mean squared error (MSE) is commonly used as the loss function, and the optimizer updates the model weights during training to minimize the loss.\n",
    "\n",
    "Model training: The model is then trained on the training data using a process called backpropagation. This involves repeatedly passing the input features through the model, comparing the predicted target value with the actual target value, and adjusting the model weights to reduce the difference between the two. The process is repeated until the loss function converges to a minimum value.\n",
    "\n",
    "Model evaluation: Finally, the trained model is evaluated on the test data to determine its performance. A common evaluation metric for regression problems is the mean squared error (MSE), which measures the average difference between the predicted and actual target values.\n",
    "\n",
    "This simple ANN for regression can be used to model complex relationships between the input features and target variable, and can be easily modified and expanded to handle more complex problems.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "9b7rW-6J_JEZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "dpGN30Sep_UV",
    "outputId": "b36f33af-ef24-4c10-dc1c-1a32dc5cd472"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(\"TensorFlow version\",tf.__version__)\n",
    "print(\"Keras version\",keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQzzN3kppVbZ"
   },
   "source": [
    "\n",
    "# **Split the data into Testing and Training sets**\n",
    "This code splits the data into two parts, training set and testing set.\n",
    "The training set is used to train the model, while the testing set is used to evaluate its performance.\n",
    "The train_test_split function from the sklearn library is used for this.\n",
    "It takes the data and splits it into two parts with a ratio of 80:20, with the training set being 80% and the testing set being 20%.\n",
    "The test_size argument is used to specify the size of the testing set.\n",
    "The random_state argument is used to set a random seed, so that the results are reproducible.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "_2w4QXGaF092"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set_full,test_set = train_test_split(data,test_size=0.2,random_state=42)\n",
    "train_set,val_set = train_test_split(train_set_full,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Ba5_9g8IGJjj"
   },
   "outputs": [],
   "source": [
    "train_set_labels = train_set['Z_VI']\n",
    "test_set_labels = test_set['Z_VI']\n",
    "val_set_labels = val_set['Z_VI']\n",
    "\n",
    "train_set_inp = train_set[['U_MAG','G_MAG','R_MAG','I_MAG','Z_MAG','U-G_COLOR','G-R_COLOR','R-I_COLOR','I-Z_COLOR']]\n",
    "test_set_inp = test_set[['U_MAG','G_MAG','R_MAG','I_MAG','Z_MAG','U-G_COLOR','G-R_COLOR','R-I_COLOR','I-Z_COLOR']]\n",
    "val_set_inp = val_set[['U_MAG','G_MAG','R_MAG','I_MAG','Z_MAG','U-G_COLOR','G-R_COLOR','R-I_COLOR','I-Z_COLOR']]\n",
    "\n",
    "#train_set_inp = train_set[['U_MAG','G_MAG','R_MAG','I_MAG','Z_MAG','U_EXT','G_EXT','R_EXT','I_EXT','Z_EXT','U-G_COLOR','G-R_COLOR','R-I_COLOR','I-Z_COLOR']]\n",
    "#test_set_inp = test_set[['U_MAG','G_MAG','R_MAG','I_MAG','Z_MAG','U_EXT','G_EXT','R_EXT','I_EXT','Z_EXT','U-G_COLOR','G-R_COLOR','R-I_COLOR','I-Z_COLOR']]\n",
    "#val_set_inp = val_set[['U_MAG','G_MAG','R_MAG','I_MAG','Z_MAG','U_EXT','G_EXT','R_EXT','I_EXT','Z_EXT','U-G_COLOR','G-R_COLOR','R-I_COLOR','I-Z_COLOR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "8LmMoLUFGx5V",
    "outputId": "ee7152b0-307f-4297-86da-a78f273c6b49"
   },
   "outputs": [],
   "source": [
    "print(train_set_inp.shape,val_set_inp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwiJwjwYmBFr"
   },
   "source": [
    "# **Wider Network**\n",
    "Less number of hidden layers, but increase the number of neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "qxMB7xP7_Kop",
    "outputId": "4d3a9cd3-7e6d-4fa1-cd71-9b4ba2db9b92"
   },
   "outputs": [],
   "source": [
    "# Creating a sequential model using the Keras API from Tensorflow library\n",
    "#The first layer with 14 neurons and relu activation function\n",
    "# The output layer with 1 neuron\n",
    "wmodel = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(9,)),\n",
    "    tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "#Compiling the model using the Adam optimizer and mean squared error loss function\n",
    "wmodel.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss='mean_squared_error',metrics=[\"accuracy\"])\n",
    "# Training the model with the train data and setting number of epochs to 100\n",
    "whistory = wmodel.fit(train_set_inp, train_set_labels, epochs=50, validation_data=(val_set_inp,val_set_labels), verbose=True)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss = wmodel.evaluate(test_set_inp, test_set_labels, verbose=True)\n",
    "print(f'Test loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "rOGGrk1h4JmS",
    "outputId": "8b6aa47c-43b9-44a1-b5a8-20f5dfaf68b9"
   },
   "outputs": [],
   "source": [
    "!pip3 install ann_visualizer\n",
    "!pip3 install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "zl6XMIOB4skS"
   },
   "outputs": [],
   "source": [
    "\n",
    "from ann_visualizer.visualize import ann_viz;\n",
    "#Build your model here\n",
    "ann_viz(wmodel,view=True,title='wideANN',filename='wideANN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bgNdo2xMrAqb"
   },
   "source": [
    "# **Model Summary**\n",
    "The model.summary() function will provide a summary of the Neural Network model, including the number of layers, number of parameters in each layer, total number of parameters, and the shape of the input and output layers. The summary will give us an overall idea of the architecture of the model and help us to understand the model better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "TsJeQiMYMDRW",
    "outputId": "5fa02c2a-38db-4ce3-ede2-a791c9805ff7"
   },
   "outputs": [],
   "source": [
    "wmodel.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "tZAdIqKHyvKu",
    "outputId": "8c8abc5e-840f-4581-ac49-1679bd5d1fb2"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    wmodel,\n",
    "    to_file=\"wmodel.png\",\n",
    "    show_shapes=True,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=96,\n",
    "    layer_range=None,\n",
    "    show_layer_activations=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "id": "uNvtlrg7v20S",
    "outputId": "8992bbf8-dc0a-4eca-c11b-64f1040c07d4"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(whistory.history).plot(figsize=(12,5))\n",
    "plt.grid()\n",
    "whistory.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CPD0iQiHpJVm"
   },
   "source": [
    "\n",
    "# **Deeper network**\n",
    "less number of neurons, but high number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "mwM-Q-BCHNTH"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "A8ertFY0mS7s",
    "outputId": "a0d0d16c-56c7-4030-b415-d9ffd3c0b17a"
   },
   "outputs": [],
   "source": [
    "dmodel = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation='relu', input_shape=(9,)),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dense(15, activation='relu'),\n",
    "    tf.keras.layers.Dense(7, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "# Compile the model\n",
    "dmodel.compile(optimizer=tf.keras.optimizers.Nadam(0.001),\n",
    "              loss='mean_squared_error',metrics=[\"accuracy\"])\n",
    "# Train the model\n",
    "dhistory = dmodel.fit(train_set_inp, train_set_labels, epochs=50, validation_data=(val_set_inp,val_set_labels),verbose=True)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss = dmodel.evaluate(test_set_inp, test_set_labels, verbose=True)\n",
    "print(f'Test loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "id": "gwGjWQrjdJTh",
    "outputId": "39341a6f-d99f-4241-92e8-570a338c6ef6"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(dhistory.history).plot(figsize=(12,5))\n",
    "plt.grid()\n",
    "dhistory.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "NTiisEzLpfP4",
    "outputId": "633b94fc-1def-4047-f9d6-ec62a9ccf1ff"
   },
   "outputs": [],
   "source": [
    "dmodel.summary()\n",
    "tf.keras.utils.plot_model(\n",
    "    dmodel,\n",
    "    to_file=\"dmodel.png\",\n",
    "    show_shapes=True,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=96,\n",
    "    layer_range=None,\n",
    "    show_layer_activations=True,\n",
    ")\n",
    "ann_viz(dmodel,view=True,title='deepANN',filename='deepANN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "C6KiQOqyprGN",
    "outputId": "a6da721a-3493-49e1-9e4c-c5639943a5b2"
   },
   "outputs": [],
   "source": [
    "#This code is creating a line plot to compare the loss of two different neural network models,\n",
    "#one with a wider network and one with a deeper network, as a function of the number of epochs.\n",
    "fig,ax=plt.subplots(figsize=(8,6))\n",
    "ax.plot(np.arange(50),whistory.history['loss'],label='Wider Network')\n",
    "ax.plot(np.arange(50),dhistory.history['loss'],label='Deeper Network')\n",
    "ax.set(xlabel='n_epochs',ylabel='Loss',title='Wider vs Deeper')\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "pY0PC_LoXYU0",
    "outputId": "58b17650-ac6f-4206-9862-219fecd8b4ab"
   },
   "outputs": [],
   "source": [
    "!pip install scikeras\n",
    "#Scikit-Learn compatible wrappers for Keras Models. Why SciKeras. SciKeras is derived from and API compatible with tf.keras.wrappers.scikit_learn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "le4nsqvu3Bt-"
   },
   "source": [
    "# **Implement Cross-validation for better generalization**\n",
    "This code is a demonstration of how to build and evaluate a simple neural network using the scikit-learn library. The code performs the following steps:\n",
    "\n",
    "1. Imports necessary modules: The first few lines import modules from Tensorflow \n",
    "and scikit-learn. The Sequential class from Tensorflow is used to define the neural network architecture, while the Dense class is used to add dense (fully connected) layers to the network. The KerasRegressor class from the scikeras library is used to wrap the Tensorflow model in a scikit-learn compatible estimator. The cross_val_score function from scikit-learn's model selection module is used to evaluate the model's performance using cross-validation.\n",
    "\n",
    "2. Define the neural network architecture: The baseline_model function defines the architecture of the neural network. A sequential model is created, and two dense layers are added to it, with the first layer having 64 neurons and the second layer having 1 neuron. The activation function used in the first layer is relu, while the second layer has no activation function (the output of the model is a scalar value). The model is then compiled using mean squared error as the loss function and the adam optimizer.\n",
    "\n",
    "3. Evaluate the model: The KerasRegressor class is instantiated and passed the baseline model function as a parameter, along with other training parameters such as the number of epochs and batch size. The cross_val_score function is used to evaluate the model's performance on the input data and labels using 5-fold cross-validation, with negative mean squared error as the scoring metric. The final results are printed, showing the mean and standard deviation of the negative mean squared error.\n",
    "\n",
    "This code provides a simple example of how to use Tensorflow and scikit-learn together to build and evaluate a neural network. The scikeras library allows you to use Tensorflow models within a scikit-learn framework, making it easier to perform tasks such as model selection, feature engineering, and evaluation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mh7Ln5DgVcKE",
    "outputId": "eceb3679-661d-4382-867f-b365ab061c5e"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def baseline_model():\n",
    " # create model\n",
    " model = Sequential()\n",
    " model.add(Dense(64, input_shape=(9,), kernel_initializer='normal', activation='relu'))\n",
    " model.add(Dense(1, kernel_initializer='normal'))\n",
    " # Compile model\n",
    " model.compile(loss='mean_squared_error', optimizer='adam')\n",
    " return model\n",
    " \n",
    "# evaluate model\n",
    "estimator = KerasRegressor(model=baseline_model, epochs=50, batch_size=800, verbose=1)\n",
    "#kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(estimator, train_set_inp, train_set_labels, cv=10, scoring='neg_mean_squared_error')\n",
    "print(\"Baseline: %.4f (%.4f) MSE\" % (-results.mean(), results.std()))\n",
    "wd_mean_mse = -results.mean()\n",
    "wd_std_mse = results.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4dKYLmHWDKRi"
   },
   "source": [
    "# **Cross-validation for deeper network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "bSrxrA4LMvni"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "_519vi79_ZAx",
    "outputId": "fc95ee03-ac83-47b4-f1b4-fdfc883cf22c"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def kd_baseline_model():\n",
    " # create model\n",
    " kdmodel = Sequential()\n",
    " kdmodel.add(Dense(30, input_shape=(9,), kernel_initializer='normal', activation='relu'))\n",
    " kdmodel.add(Dense(20, kernel_initializer='normal'))\n",
    " kdmodel.add(Dense(15, kernel_initializer='normal'))\n",
    " kdmodel.add(Dense(7, kernel_initializer='normal'))\n",
    " kdmodel.add(Dense(3, kernel_initializer='normal'))\n",
    " kdmodel.add(Dense(1, kernel_initializer='normal'))\n",
    " # Compile model\n",
    " kdmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    " return kdmodel\n",
    " \n",
    "# evaluate model\n",
    "kdestimator = KerasRegressor(model=kd_baseline_model, epochs=50, batch_size=800, verbose=1)\n",
    "#kfold = KFold(n_splits=10)\n",
    "kdresults = cross_val_score(kdestimator, train_set_inp, train_set_labels, cv=10, scoring='neg_mean_squared_error')\n",
    "print(\"Baseline: %.4f (%.4f) MSE\" % (-kdresults.mean(), kdresults.std()))\n",
    "kd_mean_mse = -kdresults.mean()\n",
    "kd_std_mse = kdresults.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCjTPaRLEMXK",
    "outputId": "f3a1d701-1d49-49d7-b635-71dc93a4731d"
   },
   "outputs": [],
   "source": [
    "np.median(kdresults)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "ZSp89KfuW8Vz",
    "outputId": "534d3e3e-1d70-4dee-d572-847534ad35fd"
   },
   "outputs": [],
   "source": [
    "feature_importance=pd.DataFrame({\n",
    "    'rfc':forest_reg.feature_importances_,\n",
    "    'dt':tree_reg.feature_importances_\n",
    "},index=new_data.columns)\n",
    "feature_importance.sort_values(by='rfc',ascending=True,inplace=True)\n",
    "\n",
    "index = np.arange(len(feature_importance))\n",
    "fig, ax = plt.subplots(figsize=(18,8))\n",
    "rfc_feature=ax.barh(index,feature_importance['rfc'],0.4,color='purple',label='Random Forest')\n",
    "dt_feature=ax.barh(index+0.4,feature_importance['dt'],0.4,color='lightgreen',label='Decision Tree')\n",
    "ax.set(yticks=index+0.4,yticklabels=feature_importance.index)\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "zyoBH7AzbJXy",
    "outputId": "b7a6ba16-5617-4674-ae18-aec5025506ee"
   },
   "outputs": [],
   "source": [
    "forest_reg.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "_gvRtCoNb2rI"
   },
   "outputs": [],
   "source": [
    "def plot_model_history(history):\n",
    "    '''Plot the training and validation history for a TensorFlow network'''\n",
    "\n",
    "    # Extract loss and accuracy\n",
    "    loss = history.history['loss']\n",
    "    #val_loss = history.history['val_loss']\n",
    "    acc = history.history['accuracy']\n",
    "    #val_acc = history.history['val_accuracy']\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1,ncols=2, figsize=(10,5))\n",
    "    ax[0].plot(np.arange(n_epochs), loss, label='Training Loss')\n",
    "    #ax[0].plot(np.arange(n_epochs), val_loss, label='Validation Loss')\n",
    "    ax[0].set_title('Loss Curves')\n",
    "    ax[0].legend()\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "\n",
    "    ax[1].plot(np.arange(n_epochs), acc, label='Training Accuracy')\n",
    "    #ax[1].plot(np.arange(n_epochs), val_acc, label='Validation Accuracy')\n",
    "    ax[1].set_title('Accuracy Curves')\n",
    "    ax[1].legend()\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].set_ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmYWr7oQM6LT"
   },
   "source": [
    "### Note\n",
    "Choosing the best model architecture for a neural network can be a challenging task, and there is no one-size-fits-all solution. However, here are some general guidelines that can help:\n",
    "\n",
    "1. Start with a simple model: Start with a simple model architecture and gradually increase its complexity if necessary. This allows you to quickly gauge the potential of different architectures and avoid overcomplicating the model too quickly.\n",
    "\n",
    "2. Consider the problem type: The architecture of the network should be chosen based on the type of problem you are trying to solve. For example, convolutional neural networks (CNNs) are well suited for image classification tasks, while recurrent neural networks (RNNs) are well suited for sequence data such as speech or text.\n",
    "\n",
    "3. Experiment with different architectures: Try out different model architectures and compare their performance. This could involve trying different numbers of hidden layers, different activation functions, or different types of layer.\n",
    "\n",
    "4. Monitor overfitting: Overfitting is a common issue when training neural networks. Choose an architecture that strikes a balance between complexity and capacity to prevent overfitting. You can monitor the overfitting by keeping track of the performance on a validation set during training.\n",
    "\n",
    "5. Regularization: Regularization can help prevent overfitting. Consider using techniques such as dropout, weight decay, or early stopping to regularize the model.\n",
    "\n",
    "6. Transfer learning: If you have a similar problem with a lot of labeled data, consider using transfer learning, where a pre-trained model is fine-tuned on your data.\n",
    "\n",
    "7. Grid search or random search: To find the best hyperparameters for your model, consider using a grid search or random search. This can help you find the best combination of hyperparameters, such as the number of hidden units, learning rate, and batch size.\n",
    "\n",
    "Ultimately, choosing the best model architecture for a neural network requires a combination of intuition, trial-and-error, and a deep understanding of the problem you are trying to solve.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpY72i1s1uh-"
   },
   "source": [
    "# **XGBoost**\n",
    "XGBoost (short for eXtreme Gradient Boosting) is a powerful open-source software library for gradient boosting algorithms that are widely used in machine learning for both classification and regression tasks\n",
    "Gradient Boosting is an ensemble learning technique that combines multiple weak learning models to create a strong predictive model. \n",
    "\n",
    "The basic idea behind gradient boosting is to iteratively add new models to the ensemble, with each model trying to correct the errors of the previous models. In other words, each new model is trained on the residual errors of the previous models, and the final prediction is obtained by summing up the predictions of all the models.\n",
    "\n",
    "This code implements a regression analysis using the XGBoost library. Here's what the code does:\n",
    "\n",
    "1.Imports the XGBoost library as xgb.\n",
    "\n",
    "2.Splits the data into training and testing sets, where X_train and X_test are the input features for the training and testing sets respectively, and y_train and y_test are the corresponding labels for the training and testing sets.\n",
    "\n",
    "3.Defines the XGBoost model parameters in the \"params\" dictionary. The \"objective\" parameter specifies the learning task and loss function, \"max_depth\" specifies the maximum depth of each tree, \"eta\" specifies the learning rate, \"subsample\" specifies the fraction of observations to subsample at each step, \"colsample_bytree\" specifies the fraction of columns to use at each split, and \"n_jobs\" specifies the number of CPU cores to use (-1 means use all available cores).\n",
    "\n",
    "4.Trains the XGBoost model using the training set. The \"xgb.DMatrix\" function is used to create a DMatrix object from the input features and labels of the training set, and this DMatrix object is used to train the model using the \"xgb.train\" function and the parameters defined in the \"params\" dictionary. The trained model is stored in the \"xg_model\" variable.\n",
    "\n",
    "5.Makes predictions on the test set using the trained model. Another DMatrix object is created from the input features of the test set, and the \"predict\" method is used to obtain the predicted labels for the test set. The predicted labels are stored in the \"xg_y_pred\" variable.\n",
    "\n",
    "6.Evaluates the performance of the model on the test set. The \"mean_squared_error\" function from scikit-learn is used to calculate the mean squared error between the predicted and actual labels of the test set, and the result is stored in the \"xg_mse\" variable. Finally, the mean squared error is printed to the console using the \"print\" function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "h16VzCG2kjEq",
    "outputId": "c6a709b0-e8b7-4991-99b0-c20ce912c7ec"
   },
   "outputs": [],
   "source": [
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train = train_set_inp\n",
    "X_test = test_set_inp\n",
    "y_train = train_set_labels\n",
    "y_test = test_set_labels\n",
    "\n",
    "# Define XGBoost model parameters\n",
    "params = {\n",
    "    'objective': 'reg:squarederror', # specify the learning task and loss function\n",
    "    'max_depth': 7,                  # maximum depth of each tree\n",
    "    'eta': 0.5,                      # learning rate\n",
    "    'subsample': 0.7,                # fraction of observations to subsample at each step\n",
    "    'colsample_bytree': 0.7,         # fraction of columns to use at each split\n",
    "    'n_jobs': -1                     # use all available CPU cores\n",
    "}\n",
    "\n",
    "# Train XGBoost model\n",
    "xg_dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "xg_model = xgb.train(params, xg_dtrain)\n",
    "\n",
    "# Make predictions on test set\n",
    "xg_dtest = xgb.DMatrix(X_test)\n",
    "xg_y_pred = xg_model.predict(xg_dtest)\n",
    "\n",
    "# Evaluate model performance\n",
    "xg_mse = mean_squared_error(y_test, xg_y_pred)\n",
    "print('MSE:', xg_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "RHG-JnL9z36H",
    "outputId": "cb9ffefa-cdb4-4a66-82cb-0d9b81588096"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "# Define cross-validation parameters\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "xgscores = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, test_index in kf.split(train_set_inp):\n",
    "    X_train, X_test = train_set_inp.iloc[train_index], train_set_inp.iloc[test_index]\n",
    "    y_train, y_test = train_set_labels.iloc[train_index], train_set_labels.iloc[test_index]\n",
    "    \n",
    "    # Train XGBoost model\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    model = xgb.train(params, dtrain)\n",
    "\n",
    "    # Make predictions on test set\n",
    "    dtest = xgb.DMatrix(X_test)\n",
    "    y_pred = model.predict(dtest)\n",
    "\n",
    "    # Evaluate model performance\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    xgscores.append(mse)\n",
    "\n",
    "# Print average MSE across all folds\n",
    "print('Mean MSE:', np.mean(xgscores))\n",
    "print('Mean MSE:', np.std(xgscores))\n",
    "xg_mean_mse = np.mean(xgscores)\n",
    "xg_std_mse = np.std(xgscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "id": "t105GlKB9csz",
    "outputId": "a71dea1d-7673-427c-a131-479287930b6f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lin_mean_mse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-57a07001012c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmean_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.0870\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.103\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.05266\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.0881\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.146\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.05519\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mstd_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.006\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.014\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.0058\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.00396\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.0796\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.002\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmean_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlin_mean_mse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtree_mean_mse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mforest_mean_mse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd_mean_mse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkd_mean_mse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxg_mean_mse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mstd_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlin_std_mse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtree_std_mse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mforest_std_mse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd_std_mse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkd_std_mse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxg_std_mse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lin_mean_mse' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "archs = ['Linear Reg','Decision Tree','Random Forest','Wider ANN', 'Deeper ANN','XGBOOST']\n",
    "mean_mse = [0.0870,0.103,0.05266,0.0881,0.146,0.05519]\n",
    "std_mse = [0.006,0.014,0.0058,0.00396,0.0796,0.002]\n",
    "mean_mse = [lin_mean_mse,tree_mean_mse,forest_mean_mse,wd_mean_mse,kd_mean_mse,xg_mean_mse]\n",
    "std_mse = [lin_std_mse,tree_std_mse,forest_std_mse,wd_std_mse,kd_std_mse,xg_std_mse]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "\n",
    "ax.errorbar(np.arange(len(mean_mse))+1, mean_mse,\n",
    "            yerr=std_mse,\n",
    "            fmt='o')\n",
    "#labels = [item.get_text() for item in ax.get_xticklabels()]\n",
    "#labels[1] = 'Testing'\n",
    "\n",
    "#ax.set_xticklabels(archs,)\n",
    "#ax.set_xticks(np.arange(len(mean_mse))+1, archs, rotation='vertical')\n",
    "ax.set_xticks(np.arange(len(mean_mse))+1)\n",
    "ax.set_xticklabels(archs, minor=False, rotation=45)\n",
    "ax.set_xlabel('ML model')\n",
    "ax.set_ylabel('MSE')\n",
    "ax.set_title('MSE comparison for different ML models')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i1j-fD_t81Lt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
